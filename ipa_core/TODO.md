# TODO
TODO (lineal, robusto, microkernel + adapters)
0) SelecciÃ³n de lecciÃ³n

SelecciÃ³n de lecciÃ³n: el sistema define language, dialect, mode (Casual/Objetivo/FonÃ©tico), goal (Se entiende/Contra objetivo), target_text, velocidad sugerida, longitud mÃ¡xima (tokens/segundos) y criterio de aceptaciÃ³n (p. ej. 
ð‘ƒ
ð¸
ð‘…
ð‘¤
PER
w
	â€‹

 mÃ¡ximo y umbral de â€œfiabilidad del intentoâ€).

1) Microkernel: carga de plugins (antes de grabar)

Carga de plugins: se cargan Language Pack del idioma/dialecto, Model Pack del LLM seleccionado (3B/7B/14B) y el Runtime Adapter correspondiente (ONNX o llama.cpp), validando compatibilidad de versiones, schema, inventario fonÃ©tico, mappings de phones y configuraciÃ³n del scoring_profile.

2) PreparaciÃ³n de referencia (antes de grabar)

PreparaciÃ³n de referencia: se genera target_ipa_phonemic desde el catÃ¡logo lÃ©xico (palabra â†’ IPA) con variantes contextuales; si mode=FonÃ©tico, se expande a target_ipa_phonetic aplicando reglas del pack (asimilaciÃ³n, reducciones permitidas, diacrÃ­ticos habilitados) y se fija el conjunto de variantes permitidas con reglas de elecciÃ³n consistentes (sin â€œescoger la mejorâ€ salvo que el modo lo autorice explÃ­citamente).

3) ReproducciÃ³n / ejemplo

ReproducciÃ³n/ejemplo: se reproduce audio de referencia (TTS local o audio del pack) y, si aplica, una guÃ­a corta del foco del intento (1â€“2 fonemas objetivo) derivada de la adaptaciÃ³n previa.

4) GrabaciÃ³n y metadatos

GrabaciÃ³n: captura a tasa fija (p. ej. 16 kHz mono), con control de clipping y ganancia; se registran metadatos del intento (dispositivo, nivel de entrada, duraciÃ³n, timestamp local).

5) DetecciÃ³n de voz (VAD) y segmentaciÃ³n

DetecciÃ³n de voz (VAD): recorte de silencios, detecciÃ³n de pausas internas y segmentaciÃ³n (por palabra/frase) si el target excede un umbral de duraciÃ³n; se calcula ratio voz/silencio.

6) Preprocesamiento + quality gates

Preprocesamiento: normalizaciÃ³n de nivel, reducciÃ³n ligera de ruido (opcional), verificaciÃ³n de duraciÃ³n mÃ­nima, proxy de SNR y detecciÃ³n de clipping; si falla validaciÃ³n, se retorna feedback operativo (â€œrepite mÃ¡s lento / mÃ¡s cerca / menos ruidoâ€) y se omite anÃ¡lisis fonÃ©tico fino.

7) Reconocimiento fonÃ©tico (Allosaurus)

Reconocimiento fonÃ©tico (Allosaurus): se obtiene observed_phone_seq por segmento; si existen timestamps o scores, se conservan; si no, se generan aproximaciones de duraciÃ³n por segmento desde VAD.

8) NormalizaciÃ³n de inventario (phones â†’ IPA consistente)

NormalizaciÃ³n de inventario: se mapea observed_phone_seq al inventario interno del Language Pack y a IPA tokenizada consistente (sÃ­mbolo base + diacrÃ­ticos segÃºn reglas del modo); se aplica polÃ­tica de colapso alofÃ³nico segÃºn mode y se marca cualquier OOV con estrategia definida (colapsar por clase, marcar como desconocido o descartar con penalizaciÃ³n).

9) AlineaciÃ³n + mÃ©trica (DP)

AlineaciÃ³n y mÃ©trica: se alinea target_ipa vs observed_ipa usando DP (Wagnerâ€“Fischer / Levenshtein) con costos ponderados por distancia articulatoria (errores cercanos penalizan menos) y peso adicional si el cambio afecta contraste que cambia significado; se obtiene lista de operaciones S/I/D y mÃ©tricas 
ð‘ƒ
ð¸
ð‘…
ð‘¤
PER
w
	â€‹

, score 0â€“100 y desglose por clase de error.

10) Prosodia/ritmo (opcional por modo/tier)

Prosodia/ritmo: si estÃ¡ habilitado por mode/tier, se calculan mÃ©tricas de pausas, velocidad y duraciones relativas por segmento (y desviaciones respecto al patrÃ³n del target); se integran al score segÃºn pesos del scoring_profile del pack (bajo en Casual, medio en Objetivo, configurable en FonÃ©tico).

11) Postprocesado de errores (selecciÃ³n 1â€“3 focos)

Postprocesado de errores: se agrupan errores por fonema y por rasgos articulatorios (sonoridad, lugar, modo; vocales: altura/redondeamiento), se filtran por â€œfiabilidad del intentoâ€ y se seleccionan 1â€“3 focos mÃ¡ximos por intento (priorizando impacto semÃ¡ntico, repeticiÃ³n histÃ³rica y baja estabilidad).

12) ConstrucciÃ³n del Error Report (JSON canÃ³nico)

Error Report: se genera un JSON canÃ³nico (independiente del runtime/modelo) con target_text, target_ipa, observed_ipa, mÃ©tricas, lista de errores con rasgos y severidad, sugerencias de delta articulatorio calculadas por reglas, contexto mode/goal/dialect y resumen de calidad de audio; este JSON es el Ãºnico input permitido al LLM.

13) GeneraciÃ³n de feedback (LLM local vÃ­a adapter)

GeneraciÃ³n de feedback: se invoca el Runtime Adapter seleccionado (ONNX o llama.cpp) para ejecutar el Model Pack con un prompt determinista que exige salida JSON; el LLM devuelve advice_short (casual/pedagÃ³gico) y advice_long (tÃ©cnico/fino), mÃ¡s drills (pares mÃ­nimos, sÃ­labas y frases) y una lÃ­nea â€œSe entiende, peroâ€¦â€ cuando goal=Se entiende o explicaciÃ³n estricta cuando goal=Contra objetivo.

14) ValidaciÃ³n y guardrails

ValidaciÃ³n y guardrails: se valida el JSON del LLM contra schema; si falla, se reintenta una sola vez con prompt de correcciÃ³n; si vuelve a fallar, se usa un generador determinista de fallback (plantillas del Language Pack) para no bloquear UX.

15) Render (UI)

Render: se muestra target_ipa (y texto), observed_ipa, score y desglose (significado/segmental/prosodia), y el feedback con control de vista corta/larga y acciones (repetir, escuchar ejemplo, practicar drills).

16) Persistencia (local)

Persistencia: se guarda historial del intento, score, errores normalizados, mÃ©tricas de calidad, confusiones frecuentes por fonema, progreso por modo y selecciÃ³n de dialecto; opcionalmente se guarda audio bajo consentimiento.

17) AdaptaciÃ³n

AdaptaciÃ³n: la siguiente lecciÃ³n prioriza fonemas/rasgos con mayor error ponderado, baja estabilidad y alta relevancia semÃ¡ntica; ajusta longitud del target y ritmo sugerido segÃºn el desempeÃ±o y la calidad de audio reciente.

18) Mantenimiento de packs (offline)

Mantenimiento de packs: se permite instalar/actualizar Language Packs y Model Packs offline; se valida firma/integridad y compatibilidad; se mantiene un Ã­ndice local para revertir versiones si un pack degrada desempeÃ±o.

19) Bench y calibraciÃ³n local

Bench y calibraciÃ³n local: se ejecuta un conjunto pequeÃ±o de casos sintÃ©ticos por idioma/modo para calibrar umbrales de fiabilidad y medir tasa de JSON vÃ¡lido del LLM, latencia y memoria por tier (3B/7B/14B), ajustando automÃ¡ticamente el tier recomendado para el dispositivo.

flowchart TD
  A[SelecciÃ³n lecciÃ³n] --> B[Carga plugins: Language/Model/Adapter]
  B --> C[Referencia: IPA + variantes]
  C --> D[GrabaciÃ³n + VAD + quality gates]
  D -->|OK| E[Allosaurus phones]
  E --> F[phonesâ†’IPA]
  F --> G[AlineaciÃ³n DP + score]
  G --> H[Error Report JSON]
  H --> I[LLM via Adapter â†’ feedback JSON]
  I --> J[ValidaciÃ³n/fallback]
  J --> K[Render]
  K --> L[Persistencia]
  L --> M[AdaptaciÃ³n]
  D -->|Falla| K
